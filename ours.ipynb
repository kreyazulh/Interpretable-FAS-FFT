{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-16T10:01:40.628622Z",
     "iopub.status.busy": "2026-02-16T10:01:40.628348Z",
     "iopub.status.idle": "2026-02-16T10:01:43.835773Z",
     "shell.execute_reply": "2026-02-16T10:01:43.835007Z",
     "shell.execute_reply.started": "2026-02-16T10:01:40.628591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import copy\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:01:43.837874Z",
     "iopub.status.busy": "2026-02-16T10:01:43.837484Z",
     "iopub.status.idle": "2026-02-16T10:01:43.842842Z",
     "shell.execute_reply": "2026-02-16T10:01:43.841955Z",
     "shell.execute_reply.started": "2026-02-16T10:01:43.837848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Clients: 10\n",
      "  Global Rounds: 3\n",
      "  Train Path: /kaggle/input/datasets/immada/casia-fasd/casia-fasd/train\n",
      "  Test Path: /kaggle/input/datasets/immada/casia-fasd/casia-fasd/test\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration\n",
    "DATA_PATH = \"/kaggle/input/datasets/immada/casia-fasd/casia-fasd/train\"\n",
    "TEST_PATH = \"/kaggle/input/datasets/immada/casia-fasd/casia-fasd/test\"\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "GLOBAL_ROUNDS = 3\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Clients: {NUM_CLIENTS}\")\n",
    "print(f\"  Global Rounds: {GLOBAL_ROUNDS}\")\n",
    "print(f\"  Train Path: {DATA_PATH}\")\n",
    "print(f\"  Test Path: {TEST_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:01:43.844363Z",
     "iopub.status.busy": "2026-02-16T10:01:43.844075Z",
     "iopub.status.idle": "2026-02-16T10:01:43.868278Z",
     "shell.execute_reply": "2026-02-16T10:01:43.867481Z",
     "shell.execute_reply.started": "2026-02-16T10:01:43.844335Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FFT+KAN feature extraction defined (14 features total)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Enhanced FFT Feature Extraction with KAN Insights\n",
    "def compute_radial_profile(magnitude_spectrum):\n",
    "    \"\"\"Compute radial average of frequency spectrum\"\"\"\n",
    "    h, w = magnitude_spectrum.shape\n",
    "    center = (h // 2, w // 2)\n",
    "    \n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    r = np.sqrt((x - center[1])**2 + (y - center[0])**2).astype(int)\n",
    "    \n",
    "    max_r = min(center)\n",
    "    radial_prof = np.zeros(max_r)\n",
    "    \n",
    "    for radius in range(max_r):\n",
    "        mask = (r == radius)\n",
    "        radial_prof[radius] = magnitude_spectrum[mask].mean() if mask.any() else 0\n",
    "    \n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "def extract_fft_features_with_kan(image_path, img_size=256):\n",
    "    \"\"\"\n",
    "    Extract FFT features + KAN-discovered patterns\n",
    "    Based on KAN findings from interpretability analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        \n",
    "        # Compute FFT\n",
    "        f_transform = np.fft.fft2(img)\n",
    "        f_shift = np.fft.fftshift(f_transform)\n",
    "        magnitude = np.abs(f_shift)\n",
    "        \n",
    "        # Radial profile\n",
    "        radial_prof = compute_radial_profile(magnitude)\n",
    "        \n",
    "        # Frequency band analysis\n",
    "        h, w = magnitude.shape\n",
    "        center = (h // 2, w // 2)\n",
    "        \n",
    "        y, x = np.ogrid[:h, :w]\n",
    "        r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
    "        \n",
    "        outer_radius = int(min(center) * 0.8)\n",
    "        inner_radius = int(min(center) * 0.5)\n",
    "        low_radius = int(min(center) * 0.3)\n",
    "        \n",
    "        high_freq_mask = (r >= inner_radius) & (r <= outer_radius)\n",
    "        low_freq_mask = r < low_radius\n",
    "        \n",
    "        high_freq_energy = magnitude[high_freq_mask].sum()\n",
    "        low_freq_energy = magnitude[low_freq_mask].sum()\n",
    "        total_energy = magnitude.sum()\n",
    "        \n",
    "        # ===== ORIGINAL 8 FEATURES =====\n",
    "        high_low_ratio = high_freq_energy / (low_freq_energy + 1e-10)\n",
    "        high_freq_percentage = (high_freq_energy / total_energy) * 100\n",
    "        radial_mean = radial_prof.mean()\n",
    "        radial_std = radial_prof.std()\n",
    "        radial_slope = np.polyfit(range(len(radial_prof)), radial_prof, 1)[0]\n",
    "        \n",
    "        \n",
    "        # 1. Optimal Ratio Zone Score (KAN found optimal zone at ~0.18)\n",
    "        optimal_ratio_score = np.exp(-((high_low_ratio - 0.18) ** 2) / (2 * 0.02 ** 2))\n",
    "        \n",
    "        # 2. Critical Slope Threshold (KAN found -2σ threshold)\n",
    "        slope_threshold_violation = 1.0 if radial_slope < -3500 else 0.0\n",
    "        \n",
    "        # 3. Variance-based Spoof Score (KAN found high variance = spoof)\n",
    "        variance_spoof_score = radial_std / (radial_mean + 1e-10)\n",
    "        \n",
    "        # 4. Quadratic Decay (steeper = spoof)\n",
    "        x_prof = np.arange(len(radial_prof))\n",
    "        poly_coeffs = np.polyfit(x_prof, np.log1p(radial_prof), 2)\n",
    "        quadratic_decay = poly_coeffs[0]\n",
    "        \n",
    "        # 5. High-Frequency Deficit\n",
    "        high_freq_deficit = max(0, 8e6 - high_freq_energy)\n",
    "        \n",
    "        # 6. Energy Distribution Uniformity\n",
    "        mid_radius = int(min(center) * 0.5)\n",
    "        mid_freq_mask = (r >= low_radius) & (r < mid_radius)\n",
    "        mid_freq_energy = magnitude[mid_freq_mask].sum()\n",
    "        energy_uniformity = np.std([low_freq_energy, mid_freq_energy, high_freq_energy]) / (total_energy + 1e-10)\n",
    "        \n",
    "        features = {\n",
    "            # Original 8\n",
    "            'high_freq_energy': high_freq_energy,\n",
    "            'low_freq_energy': low_freq_energy,\n",
    "            'high_low_ratio': high_low_ratio,\n",
    "            'high_freq_percentage': high_freq_percentage,\n",
    "            'radial_profile_mean': radial_mean,\n",
    "            'radial_profile_std': radial_std,\n",
    "            'radial_profile_slope': radial_slope,\n",
    "            'total_energy': total_energy,\n",
    "            \n",
    "            # KAN-discovered 6\n",
    "            'optimal_ratio_score': optimal_ratio_score,\n",
    "            'slope_threshold_violation': slope_threshold_violation,\n",
    "            'variance_spoof_score': variance_spoof_score,\n",
    "            'quadratic_decay': quadratic_decay,\n",
    "            'high_freq_deficit': high_freq_deficit,\n",
    "            'energy_uniformity': energy_uniformity,\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"✓ FFT+KAN feature extraction defined (14 features total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:01:43.869401Z",
     "iopub.status.busy": "2026-02-16T10:01:43.869143Z",
     "iopub.status.idle": "2026-02-16T10:16:51.854347Z",
     "shell.execute_reply": "2026-02-16T10:16:51.853233Z",
     "shell.execute_reply.started": "2026-02-16T10:01:43.869364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LIVE V1 (high quality) images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live V1: 100%|██████████| 9591/9591 [01:06<00:00, 144.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing SPOOF (all quality) images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spoof All: 100%|██████████| 38736/38736 [14:00<00:00, 46.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLIENT DATA DISTRIBUTION\n",
      "============================================================\n",
      "Client  1: V1=200, Spoof=200, Total=400\n",
      "Client  2: V1=145, Spoof=145, Total=290\n",
      "Client  3: V1=167, Spoof=167, Total=334\n",
      "Client  4: V1=237, Spoof=237, Total=474\n",
      "Client  5: V1=146, Spoof=146, Total=292\n",
      "Client  6: V1=147, Spoof=147, Total=294\n",
      "Client  7: V1=145, Spoof=145, Total=290\n",
      "Client  8: V1=211, Spoof=211, Total=422\n",
      "Client  9: V1=185, Spoof=185, Total=370\n",
      "Client 10: V1=102, Spoof=102, Total=204\n",
      "\n",
      "============================================================\n",
      "TOTAL V1 (High-Quality Live):  1685\n",
      "TOTAL Spoof:                   1685\n",
      "TOTAL Training Samples:        3370\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Prepare Federated Training Data (V1 + V2 - Both Quality Levels)\n",
    "def prepare_federated_clients():\n",
    "    \"\"\"\n",
    "    Prepare client data with BOTH quality levels for training\n",
    "    - Live: V1 (high quality) + V2 (low quality)  ← CHANGED\n",
    "    - Spoof: All versions\n",
    "    \"\"\"\n",
    "    clients = defaultdict(lambda: {\"features\": [], \"labels\": []})\n",
    "    \n",
    "    live_dir = os.path.join(DATA_PATH, \"live\")\n",
    "    spoof_dir = os.path.join(DATA_PATH, \"spoof\")\n",
    "    \n",
    "    # -------- LIVE (V1 + V2 - both quality levels) ----------\n",
    "    print(\"Processing LIVE images (V1 + V2 - all quality)...\")\n",
    "    live_files = [f for f in os.listdir(live_dir) if \"v1\" in f or \"v2\" in f]\n",
    "    \n",
    "    for file in tqdm(live_files, desc=\"Live V1+V2\"):\n",
    "        match = re.search(r'bs(\\d+)v', file)\n",
    "        if match:\n",
    "            client_id = int(match.group(1))\n",
    "            full_path = os.path.join(live_dir, file)\n",
    "            \n",
    "            features = extract_fft_features_with_kan(full_path)\n",
    "            if features is not None:\n",
    "                clients[client_id][\"features\"].append(features)\n",
    "                clients[client_id][\"labels\"].append(0)  # live = 0\n",
    "    \n",
    "    # -------- SPOOF (all) ----------\n",
    "    print(\"\\nProcessing SPOOF (all quality) images...\")\n",
    "    spoof_per_client = defaultdict(list)\n",
    "    \n",
    "    spoof_files = os.listdir(spoof_dir)\n",
    "    for file in tqdm(spoof_files, desc=\"Spoof All\"):\n",
    "        match = re.search(r's(\\d+)v', file)\n",
    "        if match:\n",
    "            client_id = int(match.group(1))\n",
    "            full_path = os.path.join(spoof_dir, file)\n",
    "            \n",
    "            features = extract_fft_features_with_kan(full_path)\n",
    "            if features is not None:\n",
    "                spoof_per_client[client_id].append((features, 1))  # spoof = 1\n",
    "    \n",
    "    # Balance: match spoof count to live count for each client\n",
    "    for client_id in range(1, NUM_CLIENTS + 1):\n",
    "        spoof_samples = spoof_per_client[client_id]\n",
    "        num_live = len([l for l in clients[client_id][\"labels\"] if l == 0])\n",
    "        \n",
    "        if len(spoof_samples) >= num_live:\n",
    "            # Randomly sample to match live count\n",
    "            import random\n",
    "            random.seed(42)\n",
    "            selected = random.sample(spoof_samples, num_live)\n",
    "        else:\n",
    "            selected = spoof_samples\n",
    "        \n",
    "        for features, label in selected:\n",
    "            clients[client_id][\"features\"].append(features)\n",
    "            clients[client_id][\"labels\"].append(label)\n",
    "    \n",
    "    return clients\n",
    "\n",
    "# Prepare clients\n",
    "clients_data = prepare_federated_clients()\n",
    "\n",
    "# Display statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLIENT DATA DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_live = 0\n",
    "total_spoof = 0\n",
    "\n",
    "for client_id in range(1, NUM_CLIENTS + 1):\n",
    "    labels = clients_data[client_id][\"labels\"]\n",
    "    live_count = labels.count(0)\n",
    "    spoof_count = labels.count(1)\n",
    "    \n",
    "    total_live += live_count\n",
    "    total_spoof += spoof_count\n",
    "    \n",
    "    print(f\"Client {client_id:2d}: Live={live_count:3d}, Spoof={spoof_count:3d}, Total={len(labels):3d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"TOTAL Live (V1 + V2 - All Quality): {total_live}\")\n",
    "print(f\"TOTAL Spoof:                        {total_spoof}\")\n",
    "print(f\"TOTAL Training Samples:             {total_live + total_spoof}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:16:51.855968Z",
     "iopub.status.busy": "2026-02-16T10:16:51.855451Z",
     "iopub.status.idle": "2026-02-16T10:36:59.588218Z",
     "shell.execute_reply": "2026-02-16T10:36:59.587343Z",
     "shell.execute_reply.started": "2026-02-16T10:16:51.855944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TEST LIVE images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Live: 100%|██████████| 10128/10128 [03:07<00:00, 54.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing TEST SPOOF images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Spoof: 100%|██████████| 55658/55658 [16:59<00:00, 54.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST DATA SUMMARY\n",
      "============================================================\n",
      "Total test samples: 65786\n",
      "Real (all):  10128\n",
      "  - V1 (high quality): 4830\n",
      "  - V2 (low quality):  5298\n",
      "Spoof (all): 55658\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Prepare Test Data (Mixed Quality - V1 + V2)\n",
    "def prepare_test_data():\n",
    "    \"\"\"\n",
    "    Prepare test data with quality labels\n",
    "    - V1 live = high quality real\n",
    "    - V2 live = low quality real  \n",
    "    - All spoof\n",
    "    \"\"\"\n",
    "    live_dir = os.path.join(TEST_PATH, \"live\")\n",
    "    spoof_dir = os.path.join(TEST_PATH, \"spoof\")\n",
    "    \n",
    "    features_list = []\n",
    "    labels = []\n",
    "    is_v2_flags = []\n",
    "    \n",
    "    # -------- LIVE (V1 and V2) ----------\n",
    "    print(\"Processing TEST LIVE images...\")\n",
    "    live_files = os.listdir(live_dir)\n",
    "    \n",
    "    for file in tqdm(live_files, desc=\"Test Live\"):\n",
    "        full_path = os.path.join(live_dir, file)\n",
    "        features = extract_fft_features_with_kan(full_path)\n",
    "        \n",
    "        if features is not None:\n",
    "            features_list.append(features)\n",
    "            labels.append(0)  # real = 0\n",
    "            \n",
    "            # Check if V2 (low quality)\n",
    "            if \"v2\" in file:\n",
    "                is_v2_flags.append(1)\n",
    "            else:\n",
    "                is_v2_flags.append(0)\n",
    "    \n",
    "    # -------- SPOOF ----------\n",
    "    print(\"\\nProcessing TEST SPOOF images...\")\n",
    "    spoof_files = os.listdir(spoof_dir)\n",
    "    \n",
    "    for file in tqdm(spoof_files, desc=\"Test Spoof\"):\n",
    "        full_path = os.path.join(spoof_dir, file)\n",
    "        features = extract_fft_features_with_kan(full_path)\n",
    "        \n",
    "        if features is not None:\n",
    "            features_list.append(features)\n",
    "            labels.append(1)  # spoof = 1\n",
    "            is_v2_flags.append(0)  # not v2 real\n",
    "    \n",
    "    return features_list, labels, is_v2_flags\n",
    "\n",
    "# Prepare test data\n",
    "test_features, test_labels, test_v2_flags = prepare_test_data()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total test samples: {len(test_labels)}\")\n",
    "print(f\"Real (all):  {test_labels.count(0)}\")\n",
    "print(f\"  - V1 (high quality): {sum([1 for l, v2 in zip(test_labels, test_v2_flags) if l == 0 and v2 == 0])}\")\n",
    "print(f\"  - V2 (low quality):  {sum([1 for l, v2 in zip(test_labels, test_v2_flags) if l == 0 and v2 == 1])}\")\n",
    "print(f\"Spoof (all): {test_labels.count(1)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:36:59.589442Z",
     "iopub.status.busy": "2026-02-16T10:36:59.589241Z",
     "iopub.status.idle": "2026-02-16T10:36:59.597135Z",
     "shell.execute_reply": "2026-02-16T10:36:59.596643Z",
     "shell.execute_reply.started": "2026-02-16T10:36:59.589422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Federated SVM Client defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Federated SVM Client\n",
    "class FederatedSVMClient:\n",
    "    \"\"\"\n",
    "    FL Client with SVM and FFT+KAN features\n",
    "    \"\"\"\n",
    "    def __init__(self, client_id, features, labels):\n",
    "        self.client_id = client_id\n",
    "        \n",
    "        # Convert features to DataFrame then to numpy\n",
    "        self.X = pd.DataFrame(features).values\n",
    "        self.y = np.array(labels)\n",
    "        \n",
    "        # Local scaler and model\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = SVC(\n",
    "            kernel='rbf',\n",
    "            C=10.0,\n",
    "            gamma='scale',\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            probability=True  # For soft predictions\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train local SVM model\"\"\"\n",
    "        # Standardize\n",
    "        X_scaled = self.scaler.fit_transform(self.X)\n",
    "        \n",
    "        # Train SVM\n",
    "        self.model.fit(X_scaled, self.y)\n",
    "        \n",
    "        return {\n",
    "            'scaler_mean': self.scaler.mean_,\n",
    "            'scaler_scale': self.scaler.scale_,\n",
    "            'n_samples': len(self.X),\n",
    "            'model': copy.deepcopy(self.model),\n",
    "        }\n",
    "\n",
    "print(\"✓ Federated SVM Client defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:36:59.599407Z",
     "iopub.status.busy": "2026-02-16T10:36:59.599208Z",
     "iopub.status.idle": "2026-02-16T10:36:59.611397Z",
     "shell.execute_reply": "2026-02-16T10:36:59.610752Z",
     "shell.execute_reply.started": "2026-02-16T10:36:59.599388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Federated SVM Server defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Federated Server with Model Aggregation\n",
    "class FederatedSVMServer:\n",
    "    \"\"\"\n",
    "    FL Server - Aggregates SVM models\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.global_scaler = StandardScaler()\n",
    "        self.global_model = SVC(\n",
    "            kernel='rbf',\n",
    "            C=10.0,\n",
    "            gamma='scale',\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            probability=True\n",
    "        )\n",
    "        \n",
    "    def aggregate(self, client_updates):\n",
    "        \"\"\"Aggregate client scalers (weighted average)\"\"\"\n",
    "        total_samples = sum(update['n_samples'] for update in client_updates)\n",
    "        \n",
    "        # Weighted average of scaler parameters\n",
    "        weighted_mean = np.zeros_like(client_updates[0]['scaler_mean'])\n",
    "        weighted_scale = np.zeros_like(client_updates[0]['scaler_scale'])\n",
    "        \n",
    "        for update in client_updates:\n",
    "            weight = update['n_samples'] / total_samples\n",
    "            weighted_mean += weight * update['scaler_mean']\n",
    "            weighted_scale += weight * update['scaler_scale']\n",
    "        \n",
    "        self.global_scaler.mean_ = weighted_mean\n",
    "        self.global_scaler.scale_ = weighted_scale\n",
    "        \n",
    "        print(f\"  Aggregated {len(client_updates)} client models\")\n",
    "        print(f\"  Total training samples: {total_samples}\")\n",
    "        \n",
    "    def train_global(self, all_features, all_labels):\n",
    "        \"\"\"Train global model on aggregated data\"\"\"\n",
    "        X = pd.DataFrame(all_features).values\n",
    "        y = np.array(all_labels)\n",
    "        \n",
    "        # Use aggregated scaler\n",
    "        X_scaled = self.global_scaler.transform(X)\n",
    "        \n",
    "        # Train global SVM\n",
    "        self.global_model.fit(X_scaled, y)\n",
    "        \n",
    "        print(f\"✓ Global model trained on {len(X)} samples\")\n",
    "        \n",
    "    def evaluate(self, test_features, test_labels):\n",
    "        \"\"\"Evaluate global model\"\"\"\n",
    "        X_test = pd.DataFrame(test_features).values\n",
    "        X_test_scaled = self.global_scaler.transform(X_test)\n",
    "        \n",
    "        y_pred = self.global_model.predict(X_test_scaled)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "print(\"✓ Federated SVM Server defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:36:59.612540Z",
     "iopub.status.busy": "2026-02-16T10:36:59.612216Z",
     "iopub.status.idle": "2026-02-16T10:37:00.200850Z",
     "shell.execute_reply": "2026-02-16T10:37:00.200082Z",
     "shell.execute_reply.started": "2026-02-16T10:36:59.612511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEDERATED LEARNING TRAINING - FFT+KAN Features\n",
      "======================================================================\n",
      "\n",
      "========== ROUND 1/3 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients (Round 1): 100%|██████████| 10/10 [00:00<00:00, 150.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Aggregated 10 client models\n",
      "  Total training samples: 3370\n",
      "✓ Global model trained on 3370 samples\n",
      "Round 1 complete. Global model updated.\n",
      "\n",
      "========== ROUND 2/3 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients (Round 2): 100%|██████████| 10/10 [00:00<00:00, 164.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Aggregated 10 client models\n",
      "  Total training samples: 3370\n",
      "✓ Global model trained on 3370 samples\n",
      "Round 2 complete. Global model updated.\n",
      "\n",
      "========== ROUND 3/3 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training clients (Round 3): 100%|██████████| 10/10 [00:00<00:00, 167.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Aggregated 10 client models\n",
      "  Total training samples: 3370\n",
      "✓ Global model trained on 3370 samples\n",
      "Round 3 complete. Global model updated.\n",
      "\n",
      "✓ Federated learning complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Federated Learning Training Loop\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEDERATED LEARNING TRAINING - FFT+KAN Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize server\n",
    "server = FederatedSVMServer()\n",
    "\n",
    "# Global rounds\n",
    "for round_num in range(GLOBAL_ROUNDS):\n",
    "    print(f\"\\n========== ROUND {round_num + 1}/{GLOBAL_ROUNDS} ==========\")\n",
    "    \n",
    "    client_updates = []\n",
    "    all_round_features = []\n",
    "    all_round_labels = []\n",
    "    \n",
    "    # Train each client\n",
    "    for client_id in tqdm(range(1, NUM_CLIENTS + 1), desc=f\"Training clients (Round {round_num + 1})\"):\n",
    "        client_features = clients_data[client_id][\"features\"]\n",
    "        client_labels = clients_data[client_id][\"labels\"]\n",
    "        \n",
    "        # Create client\n",
    "        client = FederatedSVMClient(client_id, client_features, client_labels)\n",
    "        \n",
    "        # Train locally\n",
    "        update = client.train()\n",
    "        client_updates.append(update)\n",
    "        \n",
    "        # Collect for global training\n",
    "        all_round_features.extend(client_features)\n",
    "        all_round_labels.extend(client_labels)\n",
    "    \n",
    "    # Aggregate scalers\n",
    "    server.aggregate(client_updates)\n",
    "    \n",
    "    # Train global model\n",
    "    server.train_global(all_round_features, all_round_labels)\n",
    "    \n",
    "    print(f\"Round {round_num + 1} complete. Global model updated.\")\n",
    "\n",
    "print(\"\\n✓ Federated learning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T10:37:00.202443Z",
     "iopub.status.busy": "2026-02-16T10:37:00.201902Z",
     "iopub.status.idle": "2026-02-16T10:37:00.726343Z",
     "shell.execute_reply": "2026-02-16T10:37:00.725685Z",
     "shell.execute_reply.started": "2026-02-16T10:37:00.202418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EVALUATION - FFT+KAN FEDERATED MODEL\n",
      "======================================================================\n",
      "\n",
      "=== OVERALL TEST PERFORMANCE ===\n",
      "Accuracy:  0.8668\n",
      "Precision: 0.8664\n",
      "Recall:    0.9962\n",
      "F1 Score:  0.9268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1574  8554]\n",
      " [  209 55449]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.88      0.16      0.26     10128\n",
      "       Spoof       0.87      1.00      0.93     55658\n",
      "\n",
      "    accuracy                           0.87     65786\n",
      "   macro avg       0.87      0.58      0.60     65786\n",
      "weighted avg       0.87      0.87      0.82     65786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Evaluation - Overall Performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION - FFT+KAN FEDERATED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get predictions\n",
    "preds = server.evaluate(test_features, test_labels)\n",
    "true_labels = np.array(test_labels)\n",
    "\n",
    "# Overall metrics\n",
    "print(\"\\n=== OVERALL TEST PERFORMANCE ===\")\n",
    "print(f\"Accuracy:  {accuracy_score(true_labels, preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(true_labels, preds):.4f}\")\n",
    "print(f\"Recall:    {recall_score(true_labels, preds):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(true_labels, preds):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(true_labels, preds)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, preds, target_names=[\"Real\", \"Spoof\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
